{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c3ffe06-c153-4775-aa6f-ddc81745ec89",
   "metadata": {},
   "source": [
    "# Lightning to PyTorch: CIFAR-10 Classifier Comparison\n",
    "\n",
    "This notebook is part of my prep for developing skills as a research engineer in alignment science role\n",
    "\n",
    "The goal is to deeply understand PyTorch Lightning abstractions by:\n",
    "- Annotating every major component of the Lightning CIFAR-10 example\n",
    "- Rebuilding the same pipeline in plan PyTorch side-by-side\n",
    "- Documenting what Lightning automates or hides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f41b6dc-a750-44a6-a468-c35ab6d6a57d",
   "metadata": {},
   "source": [
    "## Part 1: Vanilla PyTorch Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b28ef1b-2041-4d99-a7ca-151d42855dbc",
   "metadata": {},
   "source": [
    "## Part 2: Lightning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbc39c3-fbbe-41bc-a16a-2c0cea852ee4",
   "metadata": {},
   "source": [
    "### Step 1: Import Python and Pytorch Libraries\n",
    "\n",
    "We import standard Python Libraries, Pytorch core components, and torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5340a0d3-94f7-449e-a2f4-65a6b9bc3274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d3aba2-4058-482b-8026-b637fd950207",
   "metadata": {},
   "source": [
    "### Step 2: Import Functional Tools and Dataset Utilities\n",
    "\n",
    "We'll use functional tools like 'F.cross_entropy' (calculates classification loss in the training step of the model) and dataset helpers like 'transforms' (preprocesses images when loading image data to the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf270d-3921-4b18-a633-8c9858ccde2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5218375e-9187-40a4-a307-a7b0ff17720a",
   "metadata": {},
   "source": [
    "### Step 3: Import PyTorch Lightning Core Tools\n",
    "\n",
    "We import the core PyTorch Lightning classes for model training and reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa934a-9b57-4dc2-a177-e0287177ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b3f4e8-bfd8-4ac9-b397-09b8cc2e378d",
   "metadata": {},
   "source": [
    "### Step 4: Set a Seed for Reproducibility\n",
    "\n",
    "We fix the random seed to ensure experiments are reproducible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca1a8de-e26f-4ac4-92ac-94190b15b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2bd397-3e0d-4615-9899-1a47d507d93d",
   "metadata": {},
   "source": [
    "### Step 5: Define Transform for CIFAR-10\n",
    "\n",
    "CIFAR-10 images are 32x32 color images (3 channels, RGB). We apply:\n",
    "- 'ToTensor()' to conver PIL images to PyTorch tensors\n",
    "- 'Normalize()' to scale pixel values form [0,1] to [-1,1]\n",
    "This helps model learn better and faster.\n",
    "\n",
    "The below is a data transformation pipeline to proprocess the images.\n",
    "- transforms.ToTensor() converts image to tensor, scales to [0.0, 1.0] e.g. before: pixel value is 128 out of 255, after ToTensor: 128/255 = ~0.502\n",
    "- transforms.Normalize(...) shifts and scales to [-1,1] per channel (R, G, B) e.g. after Normalize (0.502 - 0.5) / 0.5 = ~ 0.004 / 0.5 = ~ 0.008: pixel value of 0 become - 1, a pixel value of 1 becomes + 1 so range is roughly [-1, 1]\n",
    "- transforms.Compose([...]) chains the two steps into one transformation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f675c9e2-5899-47c3-a21e-16cfc7028a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02095afd-f159-43f3-ab79-e18437c8db31",
   "metadata": {},
   "source": [
    "### Step 6: Download the CIFAR-10 Trainig Set\n",
    "\n",
    "We use 'torchvision.datasets.CIFAR10' to download the training portion of the dataset\n",
    "We apply the transform so that each image is automatically preprocessed when accessed. \n",
    "\n",
    "Notes:\n",
    "root='.' -> saves data in the current directory\n",
    "train=True -> selects the training set (train=False for test set)\n",
    "download=True -> downloads the dataset if not already present\n",
    "transform=transfrom -> applies the transform preprocessing pipeline to each image when it is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb89e6-9393-4878-8635-10333ab72cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cifar_train = CIFAR10(root='.', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbef4918-4672-4165-be19-519ea2f47d3b",
   "metadata": {},
   "source": [
    "### Step 7: Split CIFAR-10 Training Set into Training and Validation Set\n",
    "\n",
    "We split the 50,000 training images into:\n",
    "- 45,0000 for training\n",
    "- 5,000 for validation\n",
    "\n",
    "So we can monitor how well the model is generalizing during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e50192-aecc-43e5-a1d8-efc579d1d14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_train, cifar_val = random_split(cifar_train, [45000, 5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1301ec7a-6e2d-44cc-8f11-d31351a6bd1a",
   "metadata": {},
   "source": [
    "### Step 8: Create DataLoaders for Training and Validation Sets\n",
    "\n",
    "We now create PyTorch DataLoaders to:\n",
    "- Shuffle and batch the training data\n",
    "- Batch (but not shuffle) the validation data\n",
    "\n",
    "Batch size controls how many images the model sees at once during training\n",
    "\n",
    "Notes:\n",
    "- for validation, we don't shuffle to ensure consistency\n",
    "- can't load 50,000 images into GPU memory at once so DataLoader gives small manageable chunks\n",
    "- Models learn better when trained on mini-batches rather than single images or full dataset\n",
    "- batch size of 64 images at a time is a common default as a good trade-off between speed and stability (less memory, sometimes better generalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef6decf-1afc-45db-a634-05a2fe86e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(cifar_train, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(cifar_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f587314-faf0-4af2-9b35-84fbfc318f59",
   "metadata": {},
   "source": [
    "### Step 9: Define the CNN Model Architecture\n",
    "\n",
    "We define a simple Convolutional Neural Network (CNN) using Pytorch's 'nn.Module'. It has:\n",
    "- Two convolutional layers\n",
    "- ReLU activations and max pooling\n",
    "- Two fully connected (linear) layers\n",
    "Takes a 3 x 32 x 32 image and outputs 10 class scores (for CIFAR-10)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7bece2-82c7-4a6d-b708-bbc20c7adc33",
   "metadata": {},
   "source": [
    "#### Step 9.1: Import CNN and activation libraries\n",
    "\n",
    "We import the core building blocks to define neural networks.\n",
    "- `nn.Module` for model classes\n",
    "- `Conv2d`, `Linear`, etc. for layers\n",
    "- `F.relu()` for activation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a59675-b449-48dd-9a63-0beef0794f8e",
   "metadata": {},
   "source": [
    "#### Step 9.2: Define the CNN Model Class\n",
    "\n",
    "We create a class `SimpleCNN` that extends `nn.Module`. This is how all PyTorch models are structured.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13ea501-9c83-4dc6-bcf3-0365ed3ecc11",
   "metadata": {},
   "source": [
    "#### Step 9.3: First Convolutional Layer\n",
    "\n",
    "This layer:\n",
    "- Takes RGB images (3 channels)\n",
    "- Applies 32 filters of size 3x3\n",
    "- Uses padding=1 to keep spatial dimensions the same\n",
    "\n",
    "Output: [B, 32, 32, 32]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3bde56-8ea4-4c44-b42e-9b1f4c0db735",
   "metadata": {},
   "source": [
    "#### Step 9.4: Max Pooling Layer\n",
    "\n",
    "Reduces each spatial dimension by half (32x32 -> 16x16) using a 2x2 max filter.\n",
    "This reduces computation and focuses on st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320c40bf-8d5f-4d6f-a561-8164b2ca3e44",
   "metadata": {},
   "source": [
    "#### Step 9.5: Second Convolutional Layer\n",
    "\n",
    "Applies 64 filters to the output of the first pooled layer.\n",
    "\n",
    "Again uses padding=1 to preserve dimensions before pooling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d42cc-6b63-46d0-a888-08cd134343a2",
   "metadata": {},
   "source": [
    "#### Step 9.6: First Fully Connected (Linear) Layer\n",
    "\n",
    "- After second pooling: output is [B, 64, 8, 8]\n",
    "- We flatten this to [B, 4096] before feeding into a dense layer\n",
    "\n",
    "This layer reduces 4096 features to 256.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f0613-0589-4f75-924a-eb804b6649db",
   "metadata": {},
   "source": [
    "#### Step 9.7: Output Layer\n",
    "\n",
    "This layer maps the 256 features to 10 output scores (one for each CIFAR-10 class).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd88ec-0f9a-41e4-ba0e-9b5c27af9049",
   "metadata": {},
   "source": [
    "#### Step 9.8: Define the Forward Pass\n",
    "\n",
    "This method defines how the input flows through the network layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f8f91b-df28-4d18-a08a-0ea47eabfc21",
   "metadata": {},
   "source": [
    "##### Note: the entire class SimpleCNN must be one block so Python knows how to build the object correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7d1d6b-7abd-4458-911f-386b8f8b31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # First conv layer: in_channels=3 (RGB), out_channels=32, kernel=3x3\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Second conv layer\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # Flattening and linear layers\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)  # 8x8 is the output size after 2 poolings\n",
    "        self.fc2 = nn.Linear(256, 10)  # 10 classes in CIFAR-10\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> [batch, 32, 16, 16]\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> [batch, 64, 8, 8]\n",
    "        x = x.view(-1, 64 * 8 * 8)            # flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe8422-2418-40b6-b8bc-a81741c8ba51",
   "metadata": {},
   "source": [
    "### Step 10: Run a Forward Pass with Dummpy Input\n",
    "\n",
    "We'll create a fake batch of CIFAR-10 images (3 channels, 32x32), pass it through the model, and check the output shape.\n",
    "\n",
    "Expected output: [batch_size, 10] - the logits for 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c71e6d0-0043-45ec-99b7-136f99b4239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a fake batch of images\n",
    "# Shape: [batch_size, channels, height, width]\n",
    "dummy_images = torch.randn(8, 3, 32, 32)  # batch of 8 RGB images\n",
    "\n",
    "# Step 2: Instantiate the model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Step 3: Forward pass\n",
    "outputs = model(dummy_images)\n",
    "\n",
    "# Step 4: Print the output shape\n",
    "print(\"Output shape:\", outputs.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cbbd55-e202-4b20-9f2a-c4a685ec5cb2",
   "metadata": {},
   "source": [
    "### Step 11: Setup Training Tools (Vanilla Pytorch)\n",
    "\n",
    "Training loop is the heart of deep learning. Basic idea:\n",
    "For each epoch (a full pass through dataset):\n",
    "1. Loop through mini-batches of your training data\n",
    "2. For each batch:\n",
    "   Run the model's forward pass (input -> model -> output; see how well the model is performing)\n",
    "   Compute the loss\n",
    "   Run backward pass to compute gradients (loss -> derivatives -> backpropagation; figure out how to adjust the weights)\n",
    "   Update weights using the optimizer\n",
    "3. Optionally evaluate on validation data\n",
    "\n",
    "Forward pass - throw the dart and see where it lands - how wrong am I?\n",
    "Backward pass - calculate how to adjust your arm to get closer next time\n",
    "\n",
    "We now define:\n",
    "- The **loss function**: Cross-entropy for classification\n",
    "- The **optimizer**: Adam optimizer for parameter updates\n",
    "- The **device**: Use GPU if available, otherwise CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849cafd9-8286-4550-a281-234c0ee0dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Step 2: Instantiate model and move it to device\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "# Step 3: Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Step 4: Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7c605-6a80-47e4-ab5f-64f845fa5f44",
   "metadata": {},
   "source": [
    "### Step 12: Training & Validation Loop (Vanilla PyTorch)\n",
    "\n",
    "We'll train the model for a few epochs using the training DataLoader.\n",
    "Each epoch consists of:\n",
    "1. Forward pass - to compute predictions\n",
    "2. Loss calculation - to measure error\n",
    "3. Backward pass - to compute gradients\n",
    "4. Optimizer step - to update weights\n",
    "\n",
    "We'll also print the avergae training loss per epoch.\n",
    "\n",
    "After each training epoch, we evaluate the model on the validation set:\n",
    "- We turn off gradient tracking with `torch.no_grad()`\n",
    "- We compute the average loss and accuracy on the validation data\n",
    "- We print these metrics to monitor generalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2131b0-4929-4930-8340-40082fbba33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf561696-7a9c-4108-a8af-f47139260e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # --- Training loop ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()              # Step 1: Reset gradients\n",
    "        outputs = model(inputs)            # Step 2: Forward pass\n",
    "        loss = criterion(outputs, labels)  # Step 3: Compute loss\n",
    "        loss.backward()                    # Step 4: Backpropagation\n",
    "        optimizer.step()                   # Step 5: Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_acc = correct / total if total > 0 else 0.0\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # --- Validation loop ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_acc = correct / total if total > 0 else 0.0\n",
    "\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    # --- Epoch summary ---\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} | \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c11f2-a4b3-4906-805b-a6f0237a396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(1, num_epochs + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00d134-26d9-4cd1-9047-28e8e3646770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = list(range(1, num_epochs + 1))\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# ---- Loss plot ----\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# ---- Accuracy plot ----\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773796ec-ec85-44ac-9693-85f3b974c5bc",
   "metadata": {},
   "source": [
    "### Step 14: Evaluate the Model on the CIFAR-10 Test Set\n",
    "\n",
    "The test set consists of 10,000 examples that were not used in training or validation.\n",
    "\n",
    "We:\n",
    "- Download the test dataset and apply the same transform\n",
    "- Create a DataLoader for batching\n",
    "- Evaluate the model’s final performance on this unseen data\n",
    "\n",
    "This is the best estimate of how well our model will generalize in the real world.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ca8ceb-881f-4194-82f6-da78e5d10377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the CIFAR-10 test set\n",
    "cifar_test = CIFAR10(root='.', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(cifar_test, batch_size=64)\n",
    "\n",
    "# Step 2: Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Step 3: Initialize counters\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Step 4: Run inference\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Step 5: Compute final metrics\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = correct / total\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f501278-4c0c-4e82-9195-7bab539890ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model parameters to a file\n",
    "torch.save(model.state_dict(), \"simple_cnn.pth\")\n",
    "print(\"Model weights saved to simple_cnn.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8575dde0-f28b-4151-b7a0-360a77d2650d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82c68b1e-54cf-46dc-a087-11cd6d0abce1",
   "metadata": {},
   "source": [
    "## Translation to PyTorch Lightning version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0d219a-4e51-4f8c-8131-c5bf157ae776",
   "metadata": {},
   "source": [
    "### Step 1: Import PyTorch Lightning\n",
    "\n",
    "We import the core Lightning module that lets us wrap our model in a training framework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c95b76-9292-4634-884d-b721b20292aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1ad1e3-1093-48ce-88d7-6c839f115a6e",
   "metadata": {},
   "source": [
    "### Step 2: Define LightningModule to Wrap the CNN\n",
    "\n",
    "We create a `LitCNN` class that extends `LightningModule`.\n",
    "\n",
    "This class defines:\n",
    "- The model (`self.model`)\n",
    "- Training logic (`training_step`)\n",
    "- Validation logic (`validation_step`)\n",
    "- Optimizer (`configure_optimizers`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b574f-8f45-4a54-a080-b3dd0f7d4614",
   "metadata": {},
   "source": [
    "e create a new class `LitCNN` that inherits from `LightningModule`. This class wraps our original `SimpleCNN` model and handles:\n",
    "\n",
    "#### 🔧 Model Instantiation (`__init__`)\n",
    "- We create an instance of our original CNN (`SimpleCNN`) and assign it to `self.model`\n",
    "- We define a loss function (`CrossEntropyLoss`) to compare predicted vs. true labels\n",
    "\n",
    "#### 🔁 Forward Pass (`forward`)\n",
    "- This is a wrapper around `self.model(x)`\n",
    "- It's used when the Trainer or another function calls `model(x)` internally\n",
    "\n",
    "#### 📉 Training Step (`training_step`)\n",
    "- This method is called **once per batch** during training\n",
    "- It receives a batch of data: `x` (inputs) and `y` (true labels)\n",
    "- It runs the forward pass to get predictions (logits)\n",
    "- Computes the loss using the criterion\n",
    "- Logs the loss using `self.log()` so Lightning can track metrics\n",
    "\n",
    "#### ✅ Validation Step (`validation_step`)\n",
    "- Same idea as `training_step`, but used on the validation set\n",
    "- In addition to loss, we also calculate accuracy:\n",
    "  - We take the class with the highest logit (`argmax`)\n",
    "  - We compare it to the ground truth and average over the batch\n",
    "\n",
    "#### ⚙️ Optimizer Setup (`configure_optimizers`)\n",
    "- We define and return our optimizer here (Adam in this case)\n",
    "- Lightning will automatically call `optimizer.step()` for us each batch\n",
    "\n",
    "---\n",
    "\n",
    "**✨ Benefits of Lightning:**\n",
    "- We no longer have to manually write training loops, validation loops, or optimizer steps\n",
    "- All the common training infrastructure is handled by the `Trainer`\n",
    "- We can scale up (e.g., to multi-GPU) or log metrics easily without changing model code\n",
    "\n",
    "Once this class is defined, we’ll use `Trainer.fit()` to train it, passing in data and hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccc9bab-45ff-4544-a74a-bb65743730a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitCNN(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = SimpleCNN()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):  # <-- THIS PART MUST BE INSIDE THE CLASS\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee50922-5965-4626-b899-7bd856b15fbc",
   "metadata": {},
   "source": [
    "### Step 3: Train the Lightning Model Using Trainer\n",
    "\n",
    "PyTorch Lightning’s `Trainer` class handles:\n",
    "- Training loop\n",
    "- Validation after each epoch\n",
    "- Progress bars and logging\n",
    "- GPU/CPU device management\n",
    "\n",
    "We just pass in:\n",
    "- Our `LitCNN` model\n",
    "- Number of training epochs\n",
    "- DataLoaders for training and validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8d5758-6886-4bd1-a89c-c4c49f5c86be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# Step 1: Instantiate the Lightning-wrapped model\n",
    "lit_model = LitCNN()\n",
    "\n",
    "# Step 2: Create a Trainer (automatic GPU if available)\n",
    "trainer = Trainer(max_epochs=5, accelerator='auto')\n",
    "\n",
    "# Step 3: Train the model\n",
    "trainer.fit(lit_model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09a08e7-66a0-46b5-abc0-3b022b27e1fd",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate the Trained Model on the Test Set\n",
    "\n",
    "Now that the model is trained, we’ll evaluate it on the official CIFAR-10 test set.\n",
    "We'll:\n",
    "- Load the test data with the same transform\n",
    "- Wrap it in a DataLoader\n",
    "- Use `trainer.test()` to run evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2654f1-2038-46e4-b22c-97f5c7cd54aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model=lit_model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c5db40-0e3e-476b-8777-28e8b5cd4063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights to disk\n",
    "torch.save(lit_model.state_dict(), \"lit_cnn_weights.pth\")\n",
    "print(\"Model weights saved to lit_cnn_weights.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3536c91d-2f72-4b2b-b495-6cab55e71f38",
   "metadata": {},
   "source": [
    "## Comparison with PyTorch Lightning\n",
    "\n",
    "Using PyTorch Lightning resulted in a slightly lower validation loss (~0.83 vs ~1.78) with similar validation accuracy (~71%). While the core model and data loaders remained the same, Lightning's abstraction may have helped with more consistent training behavior (e.g., automatic `.eval()` handling, checkpointing, device management).\n",
    "\n",
    "Overall, the takeaway is that Lightning improves code structure and reliability, especially for scaling or experimenting — but performance still depends on model capacity, data handling, and regularization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7e512a-0042-479e-90d9-11b3227d31fa",
   "metadata": {},
   "source": [
    "## 📌 Reflection & Conclusion\n",
    "\n",
    "From the training and validation curves above, it’s clear that the model quickly achieves high accuracy on the training data, with a very low training loss. However, the validation loss increases steadily while accuracy plateaus around 71–73%.\n",
    "\n",
    "This indicates **overfitting** — the model is memorizing the training data but failing to generalize well to unseen examples.\n",
    "\n",
    "### 🔍 Likely Causes\n",
    "- **Lack of regularization**: The current model doesn’t use dropout or weight decay.\n",
    "- **No data augmentation**: Images are passed as-is without techniques like flipping or cropping.\n",
    "- **Model capacity**: Even a simple CNN can overfit CIFAR-10 without proper generalization techniques.\n",
    "\n",
    "### 🛠️ Next Steps for Improvement\n",
    "- Add **dropout layers** between fully connected layers.\n",
    "- Apply **data augmentation** during training (e.g. `RandomCrop`, `RandomHorizontalFlip`).\n",
    "- Introduce **weight decay** in the optimizer.\n",
    "- Experiment with **longer training** and **early stopping** based on validation loss.\n",
    "\n",
    "Despite the overfitting, this was a valuable learning exercise in building, training, and evaluating CNNs in both **vanilla PyTorch** and **PyTorch Lightning**. It sets a solid foundation for future deep learning experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb029c5-699a-4bf9-92cc-acc797d0fd7a",
   "metadata": {},
   "source": [
    "### Why I Didn't Use a LightningDataModule Initially — and When It's Useful\n",
    "\n",
    "In this notebook, I used **explicit PyTorch DataLoaders (`train_loader`, `val_loader`, `test_loader`)** rather than implementing a `LightningDataModule` from the start.\n",
    "\n",
    "This was intentional for the following reasons:\n",
    "\n",
    "#### ✅ 1. Focus on Learning Core Concepts\n",
    "For this first round of experimentation, my primary goal was to:\n",
    "- Understand how PyTorch Lightning abstracts away training loops\n",
    "- Learn how to implement a model, training, validation, and testing steps manually\n",
    "- See the full lifecycle of a model in Lightning from scratch\n",
    "\n",
    "Using raw `DataLoader`s helped me see **exactly what Lightning is doing**, without the added abstraction of a separate data module.\n",
    "\n",
    "#### ✅ 2. Faster Iteration While Prototyping\n",
    "When you're:\n",
    "- Trying out different batch sizes\n",
    "- Quickly switching between datasets\n",
    "- Experimenting with transforms\n",
    "...it's often faster to work directly with `DataLoader`s and tweak inline.\n",
    "\n",
    "---\n",
    "\n",
    "### ⚙️ When to Use a LightningDataModule (and Why It's Powerful)\n",
    "\n",
    "As projects grow in complexity, `LightningDataModule` becomes extremely useful:\n",
    "\n",
    "#### ✅ Cleaner Organization\n",
    "All data loading logic — downloading, splitting, transforming — lives in one reusable class. This avoids copy-pasting DataLoader code between notebooks or scripts.\n",
    "\n",
    "#### ✅ Reusability\n",
    "You can plug the same `DataModule` into different models or experiments — making your codebase modular and scalable.\n",
    "\n",
    "#### ✅ Production Readiness\n",
    "If you're deploying a model or running long training jobs:\n",
    "- `prepare_data()` only downloads once (on one process)\n",
    "- `setup()` runs at the right time per training/validation/test phase\n",
    "- Easy to switch between CPU, GPU, or distributed systems\n",
    "\n",
    "#### ✅ Compatibility with `Trainer.predict()`, `Trainer.test()`, CLI training, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Summary\n",
    "\n",
    "Using explicit DataLoaders helped me:\n",
    "- Learn PyTorch Lightning’s core logic\n",
    "- Stay hands-on with each step\n",
    "- Build confidence in manual training loop concepts\n",
    "\n",
    "But for cleaner long-term experiments, I’ve now transitioned to a `CIFAR10DataModule` for better structure and scalability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a6feb6-996e-4b98-9b5c-0e7e6e4332ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20a321de-8cfe-4952-9482-ef762a68bd3f",
   "metadata": {},
   "source": [
    "### Why Performance Improvement Strategies Are Important for Future Development\n",
    "\n",
    "Once a model is successfully training and evaluating, the next step is to explore ways to **improve performance**, especially generalization to unseen data.\n",
    "\n",
    "Neural networks can often achieve **much higher accuracy** and robustness with a few thoughtful upgrades to data, architecture, or training setup.\n",
    "\n",
    "Below are common strategies that are broadly applicable in deep learning workflows:\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔁 1. Training for More Epochs\n",
    "- Training for a small number of epochs is great for prototyping.\n",
    "- For better performance, more epochs can allow the model to learn richer patterns.\n",
    "- Always monitor validation loss to avoid overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🖼️ 2. Data Augmentation\n",
    "- Applying random transformations (flips, crops, noise) makes training data more diverse.\n",
    "- Improves the model’s ability to generalize beyond what it has seen.\n",
    "- Especially effective on small or fixed-size datasets like CIFAR-10.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🧠 3. Using a Deeper or Pretrained Architecture\n",
    "- Simple models are great for learning, but deeper architectures (like ResNet, VGG, etc.) often perform much better.\n",
    "- Pretrained models from `torchvision.models` can dramatically improve results with minimal setup.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🎛️ 4. Hyperparameter Tuning\n",
    "- Learning rate, optimizer choice, and batch size can have a huge impact on model convergence and stability.\n",
    "- Systematic tuning or using libraries like `Optuna` can help discover better combinations.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🧪 5. Regularization Techniques\n",
    "- Dropout, weight decay (L2), or label smoothing help prevent overfitting.\n",
    "- These methods are often easy to add and can significantly improve robustness.\n",
    "\n",
    "---\n",
    "\n",
    "#### 🧼 6. Early Stopping and Model Checkpointing\n",
    "- Automatically save the best version of the model during training.\n",
    "- Stop training if validation accuracy stops improving.\n",
    "- Saves time and protects against overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Summary\n",
    "\n",
    "These strategies offer a roadmap for improving model performance once the training pipeline is stable. They help:\n",
    "- Boost accuracy\n",
    "- Improve generalization\n",
    "- Support robust, scalable model development\n",
    "\n",
    "As experimentation continues, combining several of these techniques thoughtfully can make a significant difference in results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f2730-91e1-4ff1-a87c-254a00831a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085adc6-97dd-4dfc-a738-5ac29b2a607b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa72791-57ba-467b-af67-0d9a05d43656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
