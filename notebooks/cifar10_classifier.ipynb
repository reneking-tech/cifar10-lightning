{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c3ffe06-c153-4775-aa6f-ddc81745ec89",
   "metadata": {},
   "source": [
    "# Lightning to PyTorch: CIFAR-10 Classifier Comparison\n",
    "\n",
    "This notebook is part of my prep for developing skills as a research engineer in alignment science role\n",
    "\n",
    "The goal is to deeply understand PyTorch Lightning abstractions by:\n",
    "- Annotating every major component of the Lightning CIFAR-10 example\n",
    "- Rebuilding the same pipeline in plan PyTorch side-by-side\n",
    "- Documenting what Lightning automates or hides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f41b6dc-a750-44a6-a468-c35ab6d6a57d",
   "metadata": {},
   "source": [
    "## Part 1: Vanilla PyTorch Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b28ef1b-2041-4d99-a7ca-151d42855dbc",
   "metadata": {},
   "source": [
    "## Part 2: Lightning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbc39c3-fbbe-41bc-a16a-2c0cea852ee4",
   "metadata": {},
   "source": [
    "### Step 1: Import Python and Pytorch Libraries\n",
    "\n",
    "We import standard Python Libraries, Pytorch core components, and torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5340a0d3-94f7-449e-a2f4-65a6b9bc3274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d3aba2-4058-482b-8026-b637fd950207",
   "metadata": {},
   "source": [
    "### Step 2: Import Functional Tools and Dataset Utilities\n",
    "\n",
    "We'll use functional tools like 'F.cross_entropy' (calculates classification loss in the training step of the model) and dataset helpers like 'transforms' (preprocesses images when loading image data to the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf270d-3921-4b18-a633-8c9858ccde2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import CIFAR10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5218375e-9187-40a4-a307-a7b0ff17720a",
   "metadata": {},
   "source": [
    "### Step 3: Import PyTorch Lightning Core Tools\n",
    "\n",
    "We import the core PyTorch Lightning classes for model training and reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa934a-9b57-4dc2-a177-e0287177ab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b3f4e8-bfd8-4ac9-b397-09b8cc2e378d",
   "metadata": {},
   "source": [
    "### Step 4: Set a Seed for Reproducibility\n",
    "\n",
    "We fix the random seed to ensure experiments are reproducible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca1a8de-e26f-4ac4-92ac-94190b15b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2bd397-3e0d-4615-9899-1a47d507d93d",
   "metadata": {},
   "source": [
    "### Step 5: Define Transform for CIFAR-10\n",
    "\n",
    "CIFAR-10 images are 32x32 color images (3 channels, RGB). We apply:\n",
    "- 'ToTensor()' to conver PIL images to PyTorch tensors\n",
    "- 'Normalize()' to scale pixel values form [0,1] to [-1,1]\n",
    "This helps model learn better and faster.\n",
    "\n",
    "The below is a data transformation pipeline to proprocess the images.\n",
    "- transforms.ToTensor() converts image to tensor, scales to [0.0, 1.0] e.g. before: pixel value is 128 out of 255, after ToTensor: 128/255 = ~0.502\n",
    "- transforms.Normalize(...) shifts and scales to [-1,1] per channel (R, G, B) e.g. after Normalize (0.502 - 0.5) / 0.5 = ~ 0.004 / 0.5 = ~ 0.008: pixel value of 0 become - 1, a pixel value of 1 becomes + 1 so range is roughly [-1, 1]\n",
    "- transforms.Compose([...]) chains the two steps into one transformation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f675c9e2-5899-47c3-a21e-16cfc7028a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02095afd-f159-43f3-ab79-e18437c8db31",
   "metadata": {},
   "source": [
    "### Step 6: Download the CIFAR-10 Trainig Set\n",
    "\n",
    "We use 'torchvision.datasets.CIFAR10' to download the training portion of the dataset\n",
    "We apply the transform so that each image is automatically preprocessed when accessed. \n",
    "\n",
    "Notes:\n",
    "root='.' -> saves data in the current directory\n",
    "train=True -> selects the training set (train=False for test set)\n",
    "download=True -> downloads the dataset if not already present\n",
    "transform=transfrom -> applies the transform preprocessing pipeline to each image when it is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb89e6-9393-4878-8635-10333ab72cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cifar_train = CIFAR10(root='.', train=True, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbef4918-4672-4165-be19-519ea2f47d3b",
   "metadata": {},
   "source": [
    "### Step 7: Split CIFAR-10 Training Set into Training and Validation Set\n",
    "\n",
    "We split the 50,000 training images into:\n",
    "- 45,0000 for training\n",
    "- 5,000 for validation\n",
    "\n",
    "So we can monitor how well the model is generalizing during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e50192-aecc-43e5-a1d8-efc579d1d14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_train, cifar_val = random_split(cifar_train, [45000, 5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1301ec7a-6e2d-44cc-8f11-d31351a6bd1a",
   "metadata": {},
   "source": [
    "### Step 8: Create DataLoaders for Training and Validation Sets\n",
    "\n",
    "We now create PyTorch DataLoaders to:\n",
    "- Shuffle and batch the training data\n",
    "- Batch (but not shuffle) the validation data\n",
    "\n",
    "Batch size controls how many images the model sees at once during training\n",
    "\n",
    "Notes:\n",
    "- for validation, we don't shuffle to ensure consistency\n",
    "- can't load 50,000 images into GPU memory at once so DataLoader gives small manageable chunks\n",
    "- Models learn better when trained on mini-batches rather than single images or full dataset\n",
    "- batch size of 64 images at a time is a common default as a good trade-off between speed and stability (less memory, sometimes better generalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef6decf-1afc-45db-a634-05a2fe86e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(cifar_train, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(cifar_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f587314-faf0-4af2-9b35-84fbfc318f59",
   "metadata": {},
   "source": [
    "### Step 9: Define the CNN Model Architecture\n",
    "\n",
    "We define a simple Convolutional Neural Network (CNN) using Pytorch's 'nn.Module'. It has:\n",
    "- Two convolutional layers\n",
    "- ReLU activations and max pooling\n",
    "- Two fully connected (linear) layers\n",
    "Takes a 3 x 32 x 32 image and outputs 10 class scores (for CIFAR-10)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7bece2-82c7-4a6d-b708-bbc20c7adc33",
   "metadata": {},
   "source": [
    "#### Step 9.1: Import CNN and activation libraries\n",
    "\n",
    "We import the core building blocks to define neural networks.\n",
    "- `nn.Module` for model classes\n",
    "- `Conv2d`, `Linear`, etc. for layers\n",
    "- `F.relu()` for activation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a59675-b449-48dd-9a63-0beef0794f8e",
   "metadata": {},
   "source": [
    "#### Step 9.2: Define the CNN Model Class\n",
    "\n",
    "We create a class `SimpleCNN` that extends `nn.Module`. This is how all PyTorch models are structured.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13ea501-9c83-4dc6-bcf3-0365ed3ecc11",
   "metadata": {},
   "source": [
    "#### Step 9.3: First Convolutional Layer\n",
    "\n",
    "This layer:\n",
    "- Takes RGB images (3 channels)\n",
    "- Applies 32 filters of size 3x3\n",
    "- Uses padding=1 to keep spatial dimensions the same\n",
    "\n",
    "Output: [B, 32, 32, 32]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3bde56-8ea4-4c44-b42e-9b1f4c0db735",
   "metadata": {},
   "source": [
    "#### Step 9.4: Max Pooling Layer\n",
    "\n",
    "Reduces each spatial dimension by half (32x32 -> 16x16) using a 2x2 max filter.\n",
    "This reduces computation and focuses on st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320c40bf-8d5f-4d6f-a561-8164b2ca3e44",
   "metadata": {},
   "source": [
    "#### Step 9.5: Second Convolutional Layer\n",
    "\n",
    "Applies 64 filters to the output of the first pooled layer.\n",
    "\n",
    "Again uses padding=1 to preserve dimensions before pooling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23d42cc-6b63-46d0-a888-08cd134343a2",
   "metadata": {},
   "source": [
    "#### Step 9.6: First Fully Connected (Linear) Layer\n",
    "\n",
    "- After second pooling: output is [B, 64, 8, 8]\n",
    "- We flatten this to [B, 4096] before feeding into a dense layer\n",
    "\n",
    "This layer reduces 4096 features to 256.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f0613-0589-4f75-924a-eb804b6649db",
   "metadata": {},
   "source": [
    "#### Step 9.7: Output Layer\n",
    "\n",
    "This layer maps the 256 features to 10 output scores (one for each CIFAR-10 class).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbd88ec-0f9a-41e4-ba0e-9b5c27af9049",
   "metadata": {},
   "source": [
    "#### Step 9.8: Define the Forward Pass\n",
    "\n",
    "This method defines how the input flows through the network layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f8f91b-df28-4d18-a08a-0ea47eabfc21",
   "metadata": {},
   "source": [
    "##### Note: the entire class SimpleCNN must be one block so Python knows how to build the object correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7d1d6b-7abd-4458-911f-386b8f8b31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # First conv layer: in_channels=3 (RGB), out_channels=32, kernel=3x3\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Second conv layer\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # Flattening and linear layers\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 256)  # 8x8 is the output size after 2 poolings\n",
    "        self.fc2 = nn.Linear(256, 10)  # 10 classes in CIFAR-10\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> [batch, 32, 16, 16]\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> [batch, 64, 8, 8]\n",
    "        x = x.view(-1, 64 * 8 * 8)            # flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe8422-2418-40b6-b8bc-a81741c8ba51",
   "metadata": {},
   "source": [
    "### Step 10: Run a Forward Pass with Dummpy Input\n",
    "\n",
    "We'll create a fake batch of CIFAR-10 images (3 channels, 32x32), pass it through the model, and check the output shape.\n",
    "\n",
    "Expected output: [batch_size, 10] - the logits for 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c71e6d0-0043-45ec-99b7-136f99b4239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a fake batch of images\n",
    "# Shape: [batch_size, channels, height, width]\n",
    "dummy_images = torch.randn(8, 3, 32, 32)  # batch of 8 RGB images\n",
    "\n",
    "# Step 2: Instantiate the model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Step 3: Forward pass\n",
    "outputs = model(dummy_images)\n",
    "\n",
    "# Step 4: Print the output shape\n",
    "print(\"Output shape:\", outputs.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cbbd55-e202-4b20-9f2a-c4a685ec5cb2",
   "metadata": {},
   "source": [
    "### Step 11: Setup Training Tools (Vanilla Pytorch)\n",
    "\n",
    "Training loop is the heart of deep learning. Basic idea:\n",
    "For each epoch (a full pass through dataset):\n",
    "1. Loop through mini-batches of your training data\n",
    "2. For each batch:\n",
    "   Run the model's forward pass (input -> model -> output; see how well the model is performing)\n",
    "   Compute the loss\n",
    "   Run backward pass to compute gradients (loss -> derivatives -> backpropagation; figure out how to adjust the weights)\n",
    "   Update weights using the optimizer\n",
    "3. Optionally evaluate on validation data\n",
    "\n",
    "Forward pass - throw the dart and see where it lands - how wrong am I?\n",
    "Backward pass - calculate how to adjust your arm to get closer next time\n",
    "\n",
    "We now define:\n",
    "- The **loss function**: Cross-entropy for classification\n",
    "- The **optimizer**: Adam optimizer for parameter updates\n",
    "- The **device**: Use GPU if available, otherwise CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849cafd9-8286-4550-a281-234c0ee0dbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Step 2: Instantiate model and move it to device\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "# Step 3: Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Step 4: Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7c605-6a80-47e4-ab5f-64f845fa5f44",
   "metadata": {},
   "source": [
    "### Step 12: Training & Validation Loop (Vanilla PyTorch)\n",
    "\n",
    "We'll train the model for a few epochs using the training DataLoader.\n",
    "Each epoch consists of:\n",
    "1. Forward pass - to compute predictions\n",
    "2. Loss calculation - to measure error\n",
    "3. Backward pass - to compute gradients\n",
    "4. Optimizer step - to update weights\n",
    "\n",
    "We'll also print the avergae training loss per epoch.\n",
    "\n",
    "After each training epoch, we evaluate the model on the validation set:\n",
    "- We turn off gradient tracking with `torch.no_grad()`\n",
    "- We compute the average loss and accuracy on the validation data\n",
    "- We print these metrics to monitor generalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2131b0-4929-4930-8340-40082fbba33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf561696-7a9c-4108-a8af-f47139260e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # --- Training loop ---\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()              # Step 1: Reset gradients\n",
    "        outputs = model(inputs)            # Step 2: Forward pass\n",
    "        loss = criterion(outputs, labels)  # Step 3: Compute loss\n",
    "        loss.backward()                    # Step 4: Backpropagation\n",
    "        optimizer.step()                   # Step 5: Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_acc = correct / total if total > 0 else 0.0\n",
    "\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # --- Validation loop ---\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_acc = correct / total if total > 0 else 0.0\n",
    "\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    # --- Epoch summary ---\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} | \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.4f} | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c11f2-a4b3-4906-805b-a6f0237a396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(1, num_epochs + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00d134-26d9-4cd1-9047-28e8e3646770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = list(range(1, num_epochs + 1))\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# ---- Loss plot ----\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# ---- Accuracy plot ----\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773796ec-ec85-44ac-9693-85f3b974c5bc",
   "metadata": {},
   "source": [
    "### Step 14: Evaluate the Model on the CIFAR-10 Test Set\n",
    "\n",
    "The test set consists of 10,000 examples that were not used in training or validation.\n",
    "\n",
    "We:\n",
    "- Download the test dataset and apply the same transform\n",
    "- Create a DataLoader for batching\n",
    "- Evaluate the model‚Äôs final performance on this unseen data\n",
    "\n",
    "This is the best estimate of how well our model will generalize in the real world.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ca8ceb-881f-4194-82f6-da78e5d10377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the CIFAR-10 test set\n",
    "cifar_test = CIFAR10(root='.', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(cifar_test, batch_size=64)\n",
    "\n",
    "# Step 2: Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Step 3: Initialize counters\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Step 4: Run inference\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Step 5: Compute final metrics\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = correct / total\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f501278-4c0c-4e82-9195-7bab539890ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model parameters to a file\n",
    "torch.save(model.state_dict(), \"simple_cnn.pth\")\n",
    "print(\"Model weights saved to simple_cnn.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8575dde0-f28b-4151-b7a0-360a77d2650d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82c68b1e-54cf-46dc-a087-11cd6d0abce1",
   "metadata": {},
   "source": [
    "## Translation to PyTorch Lightning version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0d219a-4e51-4f8c-8131-c5bf157ae776",
   "metadata": {},
   "source": [
    "### Step 1: Import PyTorch Lightning\n",
    "\n",
    "We import the core Lightning module that lets us wrap our model in a training framework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c95b76-9292-4634-884d-b721b20292aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1ad1e3-1093-48ce-88d7-6c839f115a6e",
   "metadata": {},
   "source": [
    "### Step 2: Define LightningModule to Wrap the CNN\n",
    "\n",
    "We create a `LitCNN` class that extends `LightningModule`.\n",
    "\n",
    "This class defines:\n",
    "- The model (`self.model`)\n",
    "- Training logic (`training_step`)\n",
    "- Validation logic (`validation_step`)\n",
    "- Optimizer (`configure_optimizers`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b574f-8f45-4a54-a080-b3dd0f7d4614",
   "metadata": {},
   "source": [
    "e create a new class `LitCNN` that inherits from `LightningModule`. This class wraps our original `SimpleCNN` model and handles:\n",
    "\n",
    "#### üîß Model Instantiation (`__init__`)\n",
    "- We create an instance of our original CNN (`SimpleCNN`) and assign it to `self.model`\n",
    "- We define a loss function (`CrossEntropyLoss`) to compare predicted vs. true labels\n",
    "\n",
    "#### üîÅ Forward Pass (`forward`)\n",
    "- This is a wrapper around `self.model(x)`\n",
    "- It's used when the Trainer or another function calls `model(x)` internally\n",
    "\n",
    "#### üìâ Training Step (`training_step`)\n",
    "- This method is called **once per batch** during training\n",
    "- It receives a batch of data: `x` (inputs) and `y` (true labels)\n",
    "- It runs the forward pass to get predictions (logits)\n",
    "- Computes the loss using the criterion\n",
    "- Logs the loss using `self.log()` so Lightning can track metrics\n",
    "\n",
    "#### ‚úÖ Validation Step (`validation_step`)\n",
    "- Same idea as `training_step`, but used on the validation set\n",
    "- In addition to loss, we also calculate accuracy:\n",
    "  - We take the class with the highest logit (`argmax`)\n",
    "  - We compare it to the ground truth and average over the batch\n",
    "\n",
    "#### ‚öôÔ∏è Optimizer Setup (`configure_optimizers`)\n",
    "- We define and return our optimizer here (Adam in this case)\n",
    "- Lightning will automatically call `optimizer.step()` for us each batch\n",
    "\n",
    "---\n",
    "\n",
    "**‚ú® Benefits of Lightning:**\n",
    "- We no longer have to manually write training loops, validation loops, or optimizer steps\n",
    "- All the common training infrastructure is handled by the `Trainer`\n",
    "- We can scale up (e.g., to multi-GPU) or log metrics easily without changing model code\n",
    "\n",
    "Once this class is defined, we‚Äôll use `Trainer.fit()` to train it, passing in data and hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccc9bab-45ff-4544-a74a-bb65743730a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitCNN(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = SimpleCNN()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):  # <-- THIS PART MUST BE INSIDE THE CLASS\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = self.criterion(logits, y)\n",
    "        acc = (logits.argmax(dim=1) == y).float().mean()\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee50922-5965-4626-b899-7bd856b15fbc",
   "metadata": {},
   "source": [
    "### Step 3: Train the Lightning Model Using Trainer\n",
    "\n",
    "PyTorch Lightning‚Äôs `Trainer` class handles:\n",
    "- Training loop\n",
    "- Validation after each epoch\n",
    "- Progress bars and logging\n",
    "- GPU/CPU device management\n",
    "\n",
    "We just pass in:\n",
    "- Our `LitCNN` model\n",
    "- Number of training epochs\n",
    "- DataLoaders for training and validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8d5758-6886-4bd1-a89c-c4c49f5c86be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "# Step 1: Instantiate the Lightning-wrapped model\n",
    "lit_model = LitCNN()\n",
    "\n",
    "# Step 2: Create a Trainer (automatic GPU if available)\n",
    "trainer = Trainer(max_epochs=5, accelerator='auto')\n",
    "\n",
    "# Step 3: Train the model\n",
    "trainer.fit(lit_model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09a08e7-66a0-46b5-abc0-3b022b27e1fd",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate the Trained Model on the Test Set\n",
    "\n",
    "Now that the model is trained, we‚Äôll evaluate it on the official CIFAR-10 test set.\n",
    "We'll:\n",
    "- Load the test data with the same transform\n",
    "- Wrap it in a DataLoader\n",
    "- Use `trainer.test()` to run evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2654f1-2038-46e4-b22c-97f5c7cd54aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model=lit_model, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c5db40-0e3e-476b-8777-28e8b5cd4063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights to disk\n",
    "torch.save(lit_model.state_dict(), \"lit_cnn_weights.pth\")\n",
    "print(\"Model weights saved to lit_cnn_weights.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3536c91d-2f72-4b2b-b495-6cab55e71f38",
   "metadata": {},
   "source": [
    "## Comparison with PyTorch Lightning\n",
    "\n",
    "Using PyTorch Lightning resulted in a slightly lower validation loss (~0.83 vs ~1.78) with similar validation accuracy (~71%). While the core model and data loaders remained the same, Lightning's abstraction may have helped with more consistent training behavior (e.g., automatic `.eval()` handling, checkpointing, device management).\n",
    "\n",
    "Overall, the takeaway is that Lightning improves code structure and reliability, especially for scaling or experimenting ‚Äî but performance still depends on model capacity, data handling, and regularization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7e512a-0042-479e-90d9-11b3227d31fa",
   "metadata": {},
   "source": [
    "## üìå Reflection & Conclusion\n",
    "\n",
    "From the training and validation curves above, it‚Äôs clear that the model quickly achieves high accuracy on the training data, with a very low training loss. However, the validation loss increases steadily while accuracy plateaus around 71‚Äì73%.\n",
    "\n",
    "This indicates **overfitting** ‚Äî the model is memorizing the training data but failing to generalize well to unseen examples.\n",
    "\n",
    "### üîç Likely Causes\n",
    "- **Lack of regularization**: The current model doesn‚Äôt use dropout or weight decay.\n",
    "- **No data augmentation**: Images are passed as-is without techniques like flipping or cropping.\n",
    "- **Model capacity**: Even a simple CNN can overfit CIFAR-10 without proper generalization techniques.\n",
    "\n",
    "### üõ†Ô∏è Next Steps for Improvement\n",
    "- Add **dropout layers** between fully connected layers.\n",
    "- Apply **data augmentation** during training (e.g. `RandomCrop`, `RandomHorizontalFlip`).\n",
    "- Introduce **weight decay** in the optimizer.\n",
    "- Experiment with **longer training** and **early stopping** based on validation loss.\n",
    "\n",
    "Despite the overfitting, this was a valuable learning exercise in building, training, and evaluating CNNs in both **vanilla PyTorch** and **PyTorch Lightning**. It sets a solid foundation for future deep learning experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb029c5-699a-4bf9-92cc-acc797d0fd7a",
   "metadata": {},
   "source": [
    "### Why I Didn't Use a LightningDataModule Initially ‚Äî and When It's Useful\n",
    "\n",
    "In this notebook, I used **explicit PyTorch DataLoaders (`train_loader`, `val_loader`, `test_loader`)** rather than implementing a `LightningDataModule` from the start.\n",
    "\n",
    "This was intentional for the following reasons:\n",
    "\n",
    "#### ‚úÖ 1. Focus on Learning Core Concepts\n",
    "For this first round of experimentation, my primary goal was to:\n",
    "- Understand how PyTorch Lightning abstracts away training loops\n",
    "- Learn how to implement a model, training, validation, and testing steps manually\n",
    "- See the full lifecycle of a model in Lightning from scratch\n",
    "\n",
    "Using raw `DataLoader`s helped me see **exactly what Lightning is doing**, without the added abstraction of a separate data module.\n",
    "\n",
    "#### ‚úÖ 2. Faster Iteration While Prototyping\n",
    "When you're:\n",
    "- Trying out different batch sizes\n",
    "- Quickly switching between datasets\n",
    "- Experimenting with transforms\n",
    "...it's often faster to work directly with `DataLoader`s and tweak inline.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è When to Use a LightningDataModule (and Why It's Powerful)\n",
    "\n",
    "As projects grow in complexity, `LightningDataModule` becomes extremely useful:\n",
    "\n",
    "#### ‚úÖ Cleaner Organization\n",
    "All data loading logic ‚Äî downloading, splitting, transforming ‚Äî lives in one reusable class. This avoids copy-pasting DataLoader code between notebooks or scripts.\n",
    "\n",
    "#### ‚úÖ Reusability\n",
    "You can plug the same `DataModule` into different models or experiments ‚Äî making your codebase modular and scalable.\n",
    "\n",
    "#### ‚úÖ Production Readiness\n",
    "If you're deploying a model or running long training jobs:\n",
    "- `prepare_data()` only downloads once (on one process)\n",
    "- `setup()` runs at the right time per training/validation/test phase\n",
    "- Easy to switch between CPU, GPU, or distributed systems\n",
    "\n",
    "#### ‚úÖ Compatibility with `Trainer.predict()`, `Trainer.test()`, CLI training, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Summary\n",
    "\n",
    "Using explicit DataLoaders helped me:\n",
    "- Learn PyTorch Lightning‚Äôs core logic\n",
    "- Stay hands-on with each step\n",
    "- Build confidence in manual training loop concepts\n",
    "\n",
    "But for cleaner long-term experiments, I‚Äôve now transitioned to a `CIFAR10DataModule` for better structure and scalability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a6feb6-996e-4b98-9b5c-0e7e6e4332ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20a321de-8cfe-4952-9482-ef762a68bd3f",
   "metadata": {},
   "source": [
    "### Why Performance Improvement Strategies Are Important for Future Development\n",
    "\n",
    "Once a model is successfully training and evaluating, the next step is to explore ways to **improve performance**, especially generalization to unseen data.\n",
    "\n",
    "Neural networks can often achieve **much higher accuracy** and robustness with a few thoughtful upgrades to data, architecture, or training setup.\n",
    "\n",
    "Below are common strategies that are broadly applicable in deep learning workflows:\n",
    "\n",
    "---\n",
    "\n",
    "#### üîÅ 1. Training for More Epochs\n",
    "- Training for a small number of epochs is great for prototyping.\n",
    "- For better performance, more epochs can allow the model to learn richer patterns.\n",
    "- Always monitor validation loss to avoid overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "#### üñºÔ∏è 2. Data Augmentation\n",
    "- Applying random transformations (flips, crops, noise) makes training data more diverse.\n",
    "- Improves the model‚Äôs ability to generalize beyond what it has seen.\n",
    "- Especially effective on small or fixed-size datasets like CIFAR-10.\n",
    "\n",
    "---\n",
    "\n",
    "#### üß† 3. Using a Deeper or Pretrained Architecture\n",
    "- Simple models are great for learning, but deeper architectures (like ResNet, VGG, etc.) often perform much better.\n",
    "- Pretrained models from `torchvision.models` can dramatically improve results with minimal setup.\n",
    "\n",
    "---\n",
    "\n",
    "#### üéõÔ∏è 4. Hyperparameter Tuning\n",
    "- Learning rate, optimizer choice, and batch size can have a huge impact on model convergence and stability.\n",
    "- Systematic tuning or using libraries like `Optuna` can help discover better combinations.\n",
    "\n",
    "---\n",
    "\n",
    "#### üß™ 5. Regularization Techniques\n",
    "- Dropout, weight decay (L2), or label smoothing help prevent overfitting.\n",
    "- These methods are often easy to add and can significantly improve robustness.\n",
    "\n",
    "---\n",
    "\n",
    "#### üßº 6. Early Stopping and Model Checkpointing\n",
    "- Automatically save the best version of the model during training.\n",
    "- Stop training if validation accuracy stops improving.\n",
    "- Saves time and protects against overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Summary\n",
    "\n",
    "These strategies offer a roadmap for improving model performance once the training pipeline is stable. They help:\n",
    "- Boost accuracy\n",
    "- Improve generalization\n",
    "- Support robust, scalable model development\n",
    "\n",
    "As experimentation continues, combining several of these techniques thoughtfully can make a significant difference in results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3f2730-91e1-4ff1-a87c-254a00831a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085adc6-97dd-4dfc-a738-5ac29b2a607b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa72791-57ba-467b-af67-0d9a05d43656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
